# -*- coding: utf-8 -*-
"""Sentiment_Rating.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_oYWQMPHse_EShkQ6dGMa1ers25bLEu8
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re

df = pd.read_csv("/content/apple-iphone_reviews.csv")

df.head()

"""## **Data Preprocessing**"""

df['review']= df['review'].apply(lambda x: x.lower())

# Define a function to clean the text
def clean(text):
# Removes all special characters and numericals leaving the alphabets
    text = re.sub('[^A-Za-z]+', ' ', text)
    return text
df["review"] = df["review"].apply(clean)

import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize
from nltk import pos_tag
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
from nltk.corpus import stopwords
nltk.download('wordnet')
from nltk.corpus import wordnet

# POS tagger dictionary
pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}
def token_stop_pos(text):
    tags = pos_tag(word_tokenize(text))
    newlist = []
    for word, tag in tags:
        if word.lower() not in set(stopwords.words('english')):
            newlist.append(tuple([word, pos_dict.get(tag[0])]))
    return newlist

df['POS tagged'] = df['review'].apply(token_stop_pos)
df.head()

from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()
def lemmatize(pos_data):
    lemma_rew = " "
    for word, pos in pos_data:
        if not pos:
           lemma = word
           lemma_rew = lemma_rew + " " + lemma
        else:
            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)
            lemma_rew = lemma_rew + " " + lemma
    return lemma_rew

df['review'] = df['POS tagged'].apply(lemmatize)
df.head()

"""## **Rating using Sentiment Score**"""

import nltk
nltk.download("vader_lexicon")
from nltk.sentiment.vader import SentimentIntensityAnalyzer
analyzer = SentimentIntensityAnalyzer()
# function to calculate vader sentiment
def vadersentimentanalysis(review):
    vs = analyzer.polarity_scores(review)
    #return vs['compound']
    return vs
df['Vader Sentiment'] = df['review'].apply(vadersentimentanalysis)
df.head()

df["Vader Sentiment"][0]

df["Vader Sentiment"][2]

def rate(dictionary):
    if dictionary["compound"]>=-1 and dictionary["compound"]< -0.5:
        return 1
    elif dictionary["compound"]>=-0.5 and dictionary["compound"]<0:
        return 2
    elif dictionary["compound"] == 0:
        return 3
    elif dictionary["compound"]>=0.1 and dictionary["compound"]<0.5:
        return 4
    else:
        return 5

df['Rate'] = df['Vader Sentiment'].apply(rate)

df.head()

from sklearn.metrics import mean_squared_error

mean_squared_error(df["rating"],df["Rate"])