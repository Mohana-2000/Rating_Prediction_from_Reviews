# -*- coding: utf-8 -*-
"""iphone data.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K1do3YdE4qhWlBv07kV9QPb-TCAISOxA
"""

import warnings
warnings.filterwarnings('ignore')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import re

df = pd.read_csv("/content/apple-iphone_reviews.csv")

df.head()

df.isnull().sum()

"""## **Data Preprocessing**"""

df['review']= df['review'].apply(lambda x: x.lower())

# Define a function to clean the text
def clean(text):
# Removes all special characters and numericals leaving the alphabets
    text = re.sub('[^A-Za-z]+', ' ', text)
    return text
df["review"] = df["review"].apply(clean)

import nltk
nltk.download('punkt')
from nltk.tokenize import word_tokenize
from nltk import pos_tag
nltk.download('averaged_perceptron_tagger')
nltk.download('stopwords')
from nltk.corpus import stopwords
nltk.download('wordnet')
from nltk.corpus import wordnet

# POS tagger dictionary
pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}
def token_stop_pos(text):
    tags = pos_tag(word_tokenize(text))
    newlist = []
    for word, tag in tags:
        if word.lower() not in set(stopwords.words('english')):
            newlist.append(tuple([word, pos_dict.get(tag[0])]))
    return newlist

df['POS tagged'] = df['review'].apply(token_stop_pos)
df.head()

from nltk.stem import WordNetLemmatizer
wordnet_lemmatizer = WordNetLemmatizer()
def lemmatize(pos_data):
    lemma_rew = " "
    for word, pos in pos_data:
        if not pos:
           lemma = word
           lemma_rew = lemma_rew + " " + lemma
        else:
            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)
            lemma_rew = lemma_rew + " " + lemma
    return lemma_rew

df['review'] = df['POS tagged'].apply(lemmatize)
df.head()

from sklearn.feature_extraction.text import TfidfVectorizer
tfidf = TfidfVectorizer()

X = tfidf.fit_transform(df["review"])
y = df["rating"]

X.shape,y.shape

from sklearn.model_selection import train_test_split
X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)

from sklearn.svm import LinearSVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, plot_confusion_matrix, classification_report

def run_model(model, X_train,y_train,X_test,y_test):
    model.fit(X_train,y_train)
    preds = model.predict(X_test)
    print("Accuracy: %s" % accuracy_score(preds,y_test))
    print("Classification Report:")
    print(classification_report(y_test,preds))
    print("Confusion Matrix:")
    print(plot_confusion_matrix(model,X_test,y_test))

model = LinearSVC()

run_model(model, X_train,y_train,X_test,y_test)

model = DecisionTreeClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = RandomForestClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = GradientBoostingClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = XGBClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = AdaBoostClassifier()

run_model(model, X_train,y_train,X_test,y_test)

"""In the above all algorithms, only 5 stars predicted accurately."""

df["rating"].value_counts()

sns.countplot(data = df, x = df["rating"])

"""We can see the distribution of class from the above graph. The data is imbalanced.

#### **Handling Imbalanced Data**
  - Under Sampling
  - Over Sampling
  - SMOTE

## **Under Sampling**
"""

from imblearn.under_sampling import NearMiss
nm = NearMiss()

X_res,y_res = nm.fit_resample(X,y)

X_res.shape,y_res.shape

X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)

X_train.shape,y_train.shape,X_test.shape,y_test.shape

sns.countplot(data = df, x = y_res)

model = LinearSVC()

run_model(model, X_train,y_train,X_test,y_test)

model = DecisionTreeClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = RandomForestClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = GradientBoostingClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = XGBClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = AdaBoostClassifier()

run_model(model, X_train,y_train,X_test,y_test)

"""## **Over Sampling**"""

from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state = 42)

X_ROS, y_ROS = ros.fit_resample(X, y)

X_train, X_test, y_train, y_test = train_test_split(X_ROS,y_ROS,test_size=0.2,random_state=42)

X_train.shape,y_train.shape,X_test.shape,y_test.shape

sns.countplot(data = df, x = y_ROS)

model = LinearSVC()

run_model(model, X_train,y_train,X_test,y_test)

model = DecisionTreeClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = RandomForestClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = GradientBoostingClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = XGBClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = AdaBoostClassifier()

run_model(model, X_train,y_train,X_test,y_test)

"""## **SMOTE**"""

from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state = 42)

X_smote,y_smote = smote.fit_resample(X,y)

X_train, X_test, y_train, y_test = train_test_split(X_smote,y_smote,test_size=0.2,random_state=42)

X_train.shape,y_train.shape,X_test.shape,y_test.shape

sns.countplot(data = df, x = y_smote)

model = LinearSVC()

run_model(model, X_train,y_train,X_test,y_test)

model = DecisionTreeClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = RandomForestClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = GradientBoostingClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = XGBClassifier()

run_model(model, X_train,y_train,X_test,y_test)

model = AdaBoostClassifier()

run_model(model, X_train,y_train,X_test,y_test)